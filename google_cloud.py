# -*- coding: utf-8 -*-
"""KSE_Google_Cloud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LwtwiYnGJNC2GHDpDsCbpL_N6330cmEc

# <center>  Image Analysis Service on Google Cloud

### Table of contents
1. Google Cloud package
2. Getting Google Cloud Vision API Key
3. First problem statement and dataset description
4. Second problem statement and dataset description

## [Google Cloud Vision AI](https://cloud.google.com/vision/):
- Derive insights from your images in the cloud or at the edge with AutoML Vision or use pre-trained Vision API models to detect emotion, understand text, and more.
- Detect objects automatically: Detect and classify multiple objects including the location of each object within the image. Learn more about object detection with Vision API and AutoML Vision.
- Gain intelligence at the edge: Use AutoML Vision Edge to build and deploy fast, high-accuracy models to classify images or detect objects at the edge, and trigger real-time actions based on local data. AutoML Vision Edge supports a variety of edge devices where resources are constrained and latency is critical. Learn more.
- Understand text and act on it: Vision API uses OCR to detect text within images in more than 50 languages and various file types. It’s also part of Document Understanding AI, which lets you process millions of documents quickly and automate business workflows.
- Detect explicit content: Vision API can review your images using Safe Search, and estimate the likelihood that any given image includes adult content, violence, and more.

#### Install Google Cloud package
"""

!pip install --upgrade google-cloud

!pip show google_cloud

!pip install google-cloud-vision

"""#### Import libraries"""

from google.cloud import vision
from google.cloud.vision import types

import os
import json
import urllib
import numpy as np
try:
    import cv2
except:
    !pip install opencv-python
from pylab import rcParams
from matplotlib import pyplot as plt

"""### Import Google Cloud Credentials"""

os.environ["GOOGLE_APPLICATION_CREDENTIALS"]='kse-gcp-6ee7c0274496.json'

client = vision.ImageAnnotatorClient()

"""### Text Recognition

First problem statement:

We want all our employees to not use company benefits in an unfair way and not provide fake documents. (Vision)

Today we have too many situations when employees have work trips and submit their expenses with tens of receipts from each person. Many companies do not allow submitting alcohol in their spending. But everybody knows that nobody will be able to check it in big corporations. If we ignore this problem; resources will need to increase and people will use this situation for their profit. (Issue Statement)

We will use image recognition to detect if any alcoholic drinks in receipts to help us improve our processes. (Method)

Dataset description: I created a custom receipts dataset, it consists of 20 images with 2 alcoholic receipts positive images and 18 non-alcoholic receipts images. Collection of receipts images is a tedious, time consuming and downright painful task hence the low image count. The dataset is available for download here(https://drive.google.com/drive/folders/1QK8eqsrTqCaiKv_tXV6JDtpOC6sjorKi?usp=sharing).

#### Prepare the image to analysis
"""

url1 = "https://media-cdn.tripadvisor.com/media/photo-s/0e/4c/61/59/receipt-in-ec-approximatey.jpg"
name1 = "receipt.png"

urllib.request.urlretrieve(url1, name1)

#image_to_open = 'receipt.png'
image_to_open = name1

with open(image_to_open, 'rb') as image_file:
    content = image_file.read()

def plt_show(image, title="", size = (12,10)):
    #function to plot images cleanly
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    rcParams['figure.figsize'] = size[0], size[1]
    plt.axis("off")
    plt.title(title)
    plt.imshow(image, cmap="Greys_r")
    plt.show()

import cv2
receipt = cv2.imread("receipt.png")
plt_show(receipt)

"""#### Use Google Cloud Vision AI API to analyse the image

##### Text Recognition and Positioning
"""

image1 = vision.types.Image(content=content)

text_response = client.text_detection(image=image1)

"""Show all text detected:"""

texts = [text.description for text in text_response.text_annotations]
texts

"""You can also view the location of each text detected:"""

def plt_text_result(image, text_response):
    temp = image
    
    #Loop through each text detected by Google Vision AI
    for i in range(0,len(text_response.text_annotations)):
        text = text_response.text_annotations[i]
        textloc = text.bounding_poly
        pts= np.zeros([len(textloc.vertices),2],np.int32)
        for j in range(0,len(textloc.vertices)):
            pts[j]= [textloc.vertices[j].x,textloc.vertices[j].y]
        cv2.polylines(temp,[pts],True,(0,255,0),3)
        
    plt_show(temp)

plt_text_result(receipt,text_response)

"""original text response (json format):"""

text_response

"""##### Web Entities Detection"""

web_response = client.web_detection(image=image1)

"""Google Vision AI is able to identify what the objects in the image is from previously trained model."""

entities = [item.description for item in web_response.web_detection.web_entities]
entities

"""You can also show the confidence score of each recognition."""

predictions = [(entity.description, '{:.2%}'.format(entity.score)) for entity in web_response.web_detection.web_entities]
predictions

"""Google Vision AI could generate a 'best guess' about the image:"""

web_response.web_detection.best_guess_labels
print(web_response.web_detection.best_guess_labels[0].label)

"""Finally, Google Cloud Vision AI API analysed all images of receipts and recognised wine and beer in the receipts. So, it helped us to check quickly if any alcoholic drinks in the receipt and solve our problem with receipts audit after work trips.

### Landmark Recognition

Second problem statement:

We want to find out all the names of places we’ve been even we did not have the internet to check these places or write down street names etc. (Vision)

Nowadays, we travel a lot in different countries. Sometimes we do not have the opportunity to buy new sim-card with the internet or connect to wifi to check some information online. So we lose many photos and don`t know all the information about the places that we visited and can not tell the whole story for our friends, for example. (Issue Statement)

We will use image recognition to detect the names of places to help us know all about the places that we’ve seen. (Method)

Dataset description: I created a custom dataset, it consists of 20 images with different places. So as we want just to test this idea with place recognitions, I added places from unlike places. The dataset is available for download here (https://drive.google.com/drive/folders/1CRLKNUDOxazCOGTy6Z1pWiZXwqR7b0jP?usp=sharing)
"""

url4 = "https://scontent.fybz2-2.fna.fbcdn.net/v/t1.0-9/45079340_2244747839094443_4027519377535401984_n.jpg?_nc_cat=106&_nc_sid=110474&_nc_ohc=0qM47MwH_20AX9ioh7S&_nc_ht=scontent.fybz2-2.fna&oh=c426e43440d343dde81d111ac3c03db3&oe=5EFA77FE"
name4 = "landmark.jpg"

urllib.request.urlretrieve(url4, name4)

image_to_open = name4

with open(image_to_open, 'rb') as image_file:
    content = image_file.read()
image4 = vision.types.Image(content=content)

landmark_picture = cv2.imread(name4)
plt_show(landmark_picture)

height, width = landmark_picture.shape[:2]
height, width

landmark_response = client.landmark_detection(image=image4)

for landmark in landmark_response.landmark_annotations:
    print('=' * 79)
    print(landmark)

landmark_response.landmark_annotations

def plt_landmark_result(image, lm_response):
    temp = image
    
    #Loop through each landmark detected by Google Vision AI
    for i in range(0,len(lm_response.landmark_annotations)):
        lm = lm_response.landmark_annotations[i]
        lmloc = lm.bounding_poly
        pts= np.zeros([len(lmloc.vertices),2],np.int32)
        for j in range(0,len(lmloc.vertices)):
            pts[j]= [lmloc.vertices[j].x,lmloc.vertices[j].y]
        cv2.polylines(temp,[pts],True,(0,255,0),3)
        cv2.putText(temp,str(lm.description),(int(lmloc.vertices[0].x) + 10, int(lmloc.vertices[2].y) - 10), cv2.FONT_HERSHEY_SIMPLEX,1,(0, 0, 255), thickness = 3,)
        
    plt_show(temp)

plt_landmark_result(landmark_picture, landmark_response)

"""Try your own image."""

url4a = "https://visit.sumy.ua/wp-content/uploads/2019/04/345345-1.png"
name4a = "sumy.jpg"

urllib.request.urlretrieve(url4a, name4a)

image_to_open = name4a

with open(image_to_open, 'rb') as image_file:
    content = image_file.read()
image4a = vision.types.Image(content=content)

landmark_pictureA = cv2.imread(name4a)
plt_show(landmark_pictureA)

landmark_responseA = client.landmark_detection(image=image4a)

for landmark in landmark_responseA.landmark_annotations:
    print('=' * 79)
    print(landmark)

plt_landmark_result(landmark_pictureA, landmark_responseA)

"""So we can see our result here: https://docs.google.com/spreadsheets/d/1tGxQygY6Syy4SqLkImdxYANOc8RJ8QbX008rxbrG8hA/edit?usp=sharing. Results are pretty good. Most names of the places are the same or close to the actual. It helps us to solve our problem and with GCP we will find names of places from photos."""